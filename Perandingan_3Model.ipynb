{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4545d4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba60d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengatur perangkat untuk digunakan\n",
    "# jika GPU tersedia, gunakan GPU, jika tidak, gunakan CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdde1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengubah gambar menjadi tensor\n",
    "transform = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25496094",
   "metadata": {},
   "source": [
    "**Note:** Berfungsi untuk mengubah data gambar menjadi bentuk sequnce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0b4f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menentukan hyperparameter\n",
    "input_size = 28           \n",
    "sequence_length = 28      \n",
    "hidden_size = 130         \n",
    "num_layers = 2            \n",
    "num_classes = 26          # jumlah huruf (A-Z)\n",
    "learning_rate = 0.001     \n",
    "batch_size = 200          \n",
    "num_epochs = 10           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "625e584a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download EMNIST 'letters' subset\n",
    "train_dataset = torchvision.datasets.EMNIST(root='./data',\n",
    "                                            split='letters',\n",
    "                                            train=True,\n",
    "                                            download=True,\n",
    "                                            transform=transforms.ToTensor())\n",
    "\n",
    "test_dataset = torchvision.datasets.EMNIST(root='./data',\n",
    "                                           split='letters',\n",
    "                                           train=False,\n",
    "                                           download=True,\n",
    "                                           transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeb7f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proses pengelompokan data\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5963b5",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3c72c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        \n",
    "        # Layer LSTM dengan batch_first=True berarti input berbentuk (batch, seq, feature)\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Layer fully connected untuk mengubah output LSTM menjadi prediksi kelas\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Proses LSTM, mengabaikan hidden state (_, _)\n",
    "        out, _ = self.lstm(x)\n",
    "        \n",
    "        # Ambil output dari sequence terakhir dan klasifikasikan\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e86f4a",
   "metadata": {},
   "source": [
    "**Note:**\n",
    "\n",
    "** Inisialisasi model LSTM untuk klasifikasi huruf.**\n",
    "        \n",
    "        Args:\n",
    "            input_size: ukuran input per timestep (28 piksel per baris)\n",
    "            hidden_size: jumlah unit hidden dalam LSTM\n",
    "            num_layers: jumlah layer LSTM yang ditumpuk\n",
    "            num_classes: jumlah kelas output (26 huruf A-Z)\n",
    "\n",
    "\n",
    "**Forward pass model.**\n",
    "        \n",
    "        Args:\n",
    "            x: input tensor dengan bentuk (batch_size, sequence_length, input_size)\n",
    "        \n",
    "        Returns:\n",
    "            tensor output dengan bentuk (batch_size, num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ef1def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c04753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengukur seberapa jauh hasil prediksi model dari label yang seharusnya\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# menagtur dan melakukanperubahan pada bobot di dalam model berdasarkan loss pada langkah sebelumnya\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23bcc3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/624], Loss: 1.5526\n",
      "Epoch [1/10], Step [200/624], Loss: 0.9493\n",
      "Epoch [1/10], Step [300/624], Loss: 0.5976\n",
      "Epoch [1/10], Step [400/624], Loss: 0.6800\n",
      "Epoch [1/10], Step [500/624], Loss: 0.6289\n",
      "Epoch [1/10], Step [600/624], Loss: 0.5845\n",
      "Epoch [1/10], Loss: 0.4652\n",
      "Epoch [2/10], Step [100/624], Loss: 0.4356\n",
      "Epoch [2/10], Step [200/624], Loss: 0.3397\n",
      "Epoch [2/10], Step [300/624], Loss: 0.3643\n",
      "Epoch [2/10], Step [400/624], Loss: 0.3284\n",
      "Epoch [2/10], Step [500/624], Loss: 0.4011\n",
      "Epoch [2/10], Step [600/624], Loss: 0.2830\n",
      "Epoch [2/10], Loss: 0.2921\n",
      "Epoch [3/10], Step [100/624], Loss: 0.2963\n",
      "Epoch [3/10], Step [200/624], Loss: 0.2827\n",
      "Epoch [3/10], Step [300/624], Loss: 0.4354\n",
      "Epoch [3/10], Step [400/624], Loss: 0.2626\n",
      "Epoch [3/10], Step [500/624], Loss: 0.3485\n",
      "Epoch [3/10], Step [600/624], Loss: 0.3106\n",
      "Epoch [3/10], Loss: 0.2037\n",
      "Epoch [4/10], Step [100/624], Loss: 0.2527\n",
      "Epoch [4/10], Step [200/624], Loss: 0.3568\n",
      "Epoch [4/10], Step [300/624], Loss: 0.2303\n",
      "Epoch [4/10], Step [400/624], Loss: 0.2746\n",
      "Epoch [4/10], Step [500/624], Loss: 0.1934\n",
      "Epoch [4/10], Step [600/624], Loss: 0.1856\n",
      "Epoch [4/10], Loss: 0.3465\n",
      "Epoch [5/10], Step [100/624], Loss: 0.1706\n",
      "Epoch [5/10], Step [200/624], Loss: 0.1659\n",
      "Epoch [5/10], Step [300/624], Loss: 0.1601\n",
      "Epoch [5/10], Step [400/624], Loss: 0.2243\n",
      "Epoch [5/10], Step [500/624], Loss: 0.2695\n",
      "Epoch [5/10], Step [600/624], Loss: 0.1830\n",
      "Epoch [5/10], Loss: 0.2119\n",
      "Epoch [6/10], Step [100/624], Loss: 0.1765\n",
      "Epoch [6/10], Step [200/624], Loss: 0.1309\n",
      "Epoch [6/10], Step [300/624], Loss: 0.2259\n",
      "Epoch [6/10], Step [400/624], Loss: 0.1861\n",
      "Epoch [6/10], Step [500/624], Loss: 0.1665\n",
      "Epoch [6/10], Step [600/624], Loss: 0.1389\n",
      "Epoch [6/10], Loss: 0.1431\n",
      "Epoch [7/10], Step [100/624], Loss: 0.1777\n",
      "Epoch [7/10], Step [200/624], Loss: 0.1915\n",
      "Epoch [7/10], Step [300/624], Loss: 0.2228\n",
      "Epoch [7/10], Step [400/624], Loss: 0.1696\n",
      "Epoch [7/10], Step [500/624], Loss: 0.1547\n",
      "Epoch [7/10], Step [600/624], Loss: 0.1766\n",
      "Epoch [7/10], Loss: 0.2281\n",
      "Epoch [8/10], Step [100/624], Loss: 0.1711\n",
      "Epoch [8/10], Step [200/624], Loss: 0.1290\n",
      "Epoch [8/10], Step [300/624], Loss: 0.1914\n",
      "Epoch [8/10], Step [400/624], Loss: 0.1392\n",
      "Epoch [8/10], Step [500/624], Loss: 0.1824\n",
      "Epoch [8/10], Step [600/624], Loss: 0.2342\n",
      "Epoch [8/10], Loss: 0.1935\n",
      "Epoch [9/10], Step [100/624], Loss: 0.1940\n",
      "Epoch [9/10], Step [200/624], Loss: 0.2620\n",
      "Epoch [9/10], Step [300/624], Loss: 0.1481\n",
      "Epoch [9/10], Step [400/624], Loss: 0.2571\n",
      "Epoch [9/10], Step [500/624], Loss: 0.1663\n",
      "Epoch [9/10], Step [600/624], Loss: 0.1915\n",
      "Epoch [9/10], Loss: 0.1315\n",
      "Epoch [10/10], Step [100/624], Loss: 0.1576\n",
      "Epoch [10/10], Step [200/624], Loss: 0.1617\n",
      "Epoch [10/10], Step [300/624], Loss: 0.2785\n",
      "Epoch [10/10], Step [400/624], Loss: 0.0950\n",
      "Epoch [10/10], Step [500/624], Loss: 0.0924\n",
      "Epoch [10/10], Step [600/624], Loss: 0.1803\n",
      "Epoch [10/10], Loss: 0.1152\n"
     ]
    }
   ],
   "source": [
    "# Proses pelatihan model\n",
    "total_step = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # mengubah bentuk data menjadi (batch_size, sequence_length, input_size)\n",
    "        images = images.squeeze(1).to(device)  \n",
    "        labels = labels.to(device)\n",
    "        labels = labels - 1  # menyesuaikan label ke rentang dari 0-25\n",
    "        \n",
    "        # Forward pass - lakukan prediksi\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward dan optimisasi - update bobot model\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{total_step}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91eb485",
   "metadata": {},
   "source": [
    "**Note:** \n",
    "\n",
    "Fugsi code \"images.squeeze(1).to(device)\" yaitu mengubah data kedalam bentuk sequence, dimana LSTM membutuhkan inputan dalam bentuk (batch_size, sequence_length, input_size). penjelasan detailnya yaitu awal mula bentuk inputan yaitu \n",
    "\n",
    "[batch_size, 1, 28, 28] dirubah menjadi [batch_size, 28, 28]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f5c5e754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the test images: 92.84%\n"
     ]
    }
   ],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Initialize variables for accuracy calculation\n",
    "n_correct = 0\n",
    "n_samples = 0\n",
    "\n",
    "# No need to track gradients during testing\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # Reshape and move data to device\n",
    "        images = images.squeeze(1).to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels - 1  # Adjust labels to 0-25 range\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Get predictions\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        # Update counts\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = 100.0 * n_correct / n_samples\n",
    "print(f'Accuracy of the model on the test images: {acc:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9250a131",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2a811c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size_rnn = 28           \n",
    "sequence_length_rnn = 28      \n",
    "hidden_size_rnn = 130         \n",
    "num_layers_rnn = 2            \n",
    "num_classes_rnn = 26          # jumlah huruf (A-Z)\n",
    "learning_rate_rnn = 0.001     \n",
    "batch_size_rnn = 200          \n",
    "num_epochs_rnn= 5   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "156894d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size_rnn, hidden_size_rnn, num_layers_rnn, _rnn):\n",
    "        super(RNN, self).__init__()\n",
    "        self.hidden_size = hidden_size_rnn\n",
    "        self.num_layers = num_layers_rnn\n",
    "        \n",
    "        self.rnn = nn.RNN(input_size_rnn, hidden_size_rnn, num_layers_rnn, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size_rnn, num_classes_rnn)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Menetapkan kondisi awal hidden state\n",
    "        # x: (n, 28, 28), h0: (2, n, 128)\n",
    "        # dimana n adalah ukuran batch, 28x28 adalah ukuran gambar, dan 128 adalah hidden size\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        \n",
    "        # Melakukan propagasi maju pada RNN\n",
    "        # out: (n, 28, 128)\n",
    "        # output berukuran batch_size x sequence_length x hidden_size\n",
    "        out, _ = self.rnn(x, h0)\n",
    "        \n",
    "        # Mengambil hidden state dari langkah terakhir\n",
    "        # out: (n, 128)\n",
    "        # mengambil hasil terakhir dari sequence\n",
    "        out = out[:, -1, :]\n",
    "         \n",
    "        # out: (n, 10)\n",
    "        # melakukan klasifikasi menggunakan fully connected layer\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b46aa0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rnn = RNN(input_size_rnn, hidden_size_rnn, num_layers_rnn, num_classes_rnn).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "187162df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # mengukur seberapa jauh hasil prediksi model dari label yang seharusnya\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# menagtur dan melakukanperubahan pada bobot di dalam model berdasarkan loss pada langkah sebelumnya\n",
    "optimizer_rnn = torch.optim.Adam(model_rnn.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "736f9c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/624], Loss: 2.0267\n",
      "Epoch [1/5], Step [200/624], Loss: 1.7708\n",
      "Epoch [1/5], Step [300/624], Loss: 1.6549\n",
      "Epoch [1/5], Step [400/624], Loss: 1.3486\n",
      "Epoch [1/5], Step [500/624], Loss: 1.1391\n",
      "Epoch [1/5], Step [600/624], Loss: 1.0421\n",
      "Epoch [2/5], Step [100/624], Loss: 0.9473\n",
      "Epoch [2/5], Step [200/624], Loss: 0.8995\n",
      "Epoch [2/5], Step [300/624], Loss: 0.8069\n",
      "Epoch [2/5], Step [400/624], Loss: 0.8134\n",
      "Epoch [2/5], Step [500/624], Loss: 0.7090\n",
      "Epoch [2/5], Step [600/624], Loss: 0.7328\n",
      "Epoch [3/5], Step [100/624], Loss: 0.6717\n",
      "Epoch [3/5], Step [200/624], Loss: 0.6390\n",
      "Epoch [3/5], Step [300/624], Loss: 0.7511\n",
      "Epoch [3/5], Step [400/624], Loss: 0.5626\n",
      "Epoch [3/5], Step [500/624], Loss: 0.5801\n",
      "Epoch [3/5], Step [600/624], Loss: 0.5822\n",
      "Epoch [4/5], Step [100/624], Loss: 0.6321\n",
      "Epoch [4/5], Step [200/624], Loss: 0.4542\n",
      "Epoch [4/5], Step [300/624], Loss: 0.5587\n",
      "Epoch [4/5], Step [400/624], Loss: 0.5644\n",
      "Epoch [4/5], Step [500/624], Loss: 0.6599\n",
      "Epoch [4/5], Step [600/624], Loss: 0.6550\n",
      "Epoch [5/5], Step [100/624], Loss: 0.6014\n",
      "Epoch [5/5], Step [200/624], Loss: 0.5318\n",
      "Epoch [5/5], Step [300/624], Loss: 0.5190\n",
      "Epoch [5/5], Step [400/624], Loss: 0.5965\n",
      "Epoch [5/5], Step [500/624], Loss: 0.5324\n",
      "Epoch [5/5], Step [600/624], Loss: 0.6531\n"
     ]
    }
   ],
   "source": [
    "# Melatih model\n",
    "n_total_steps_rnn = len(train_loader)\n",
    "for epoch_rnn in range(num_epochs_rnn):\n",
    "    for i, (images_rnn, labels_rnn) in enumerate(train_loader):  \n",
    "        # Mengubah bentuk gambar dari [N, 1, 28, 28] menjadi [N, 28, 28]\n",
    "        # agar sesuai dengan input RNN\n",
    "        images_rnn = images_rnn.reshape(-1, sequence_length_rnn, input_size_rnn).to(device)\n",
    "        labels_rnn = labels_rnn.to(device)\n",
    "        labels_rnn = labels_rnn - 1 \n",
    "        \n",
    "        # Melakukan prediksi dengan model\n",
    "        outputs_rnn = model_rnn(images_rnn)\n",
    "        loss_rnn = criterion(outputs_rnn, labels_rnn)\n",
    "        \n",
    "        # Memperbarui bobot model\n",
    "        optimizer_rnn.zero_grad()\n",
    "        loss_rnn.backward()\n",
    "        optimizer_rnn.step()\n",
    "        \n",
    "        # Menampilkan hasil pelatihan setiap 100 langkah\n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch_rnn+1}/{num_epochs_rnn}], Step [{i+1}/{n_total_steps_rnn}], Loss: {loss_rnn.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f3b4ca14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Akurasi model pada 10000 gambar test: 84.98076923076923 %\n"
     ]
    }
   ],
   "source": [
    "# Test model\n",
    "# Dalam fase testing,  tidak perlu menghitung gradien (untuk menghemat memori)\n",
    "with torch.no_grad():\n",
    "\n",
    "    # menghitung jumlah prediksi yang benar dan menghitung total sampel yang diuji\n",
    "    n_correct_rnn = 0  \n",
    "    n_samples_rnn = 0  \n",
    "\n",
    "    for images_rnn, labels_rnn in test_loader:\n",
    "        # Mengubah bentuk gambar agar sesuai dengan input RNN\n",
    "        images_rnn = images_rnn.reshape(-1, sequence_length_rnn, input_size_rnn).to(device)\n",
    "        labels_rnn = labels_rnn.to(device)\n",
    "        labels_rnn = labels_rnn - 1 \n",
    "        \n",
    "        # Melakukan prediksi dengan model\n",
    "        outputs_rnn = model_rnn(images_rnn)\n",
    "        \n",
    "        # Mengambil nilai prediksi tertinggi sebagai hasil prediksi\n",
    "        _, predicted_rnn = torch.max(outputs_rnn.data, 1)\n",
    "        \n",
    "        # Menghitung total sampel dan prediksi yang benar\n",
    "        n_samples_rnn += labels_rnn.size(0)\n",
    "        n_correct_rnn += (predicted_rnn == labels_rnn).sum().item()\n",
    "\n",
    "    # Menghitung akurasi dalam persen\n",
    "    acc = 100.0 * n_correct_rnn / n_samples_rnn\n",
    "    print(f'Akurasi model pada 10000 gambar test: {acc} %')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b33f90f",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7352f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUU(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(GRUU, self).__init__()\n",
    "        \n",
    "        # Layer GRU dengan batch_first=True berarti input berbentuk (batch, seq, feature)\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        \n",
    "        # Layer fully connected untuk mengubah output GRU menjadi prediksi kelas\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Proses GRU, mengabaikan hidden state (_, _)\n",
    "        out, _ = self.gru(x)\n",
    "        \n",
    "        # Ambil output dari sequence terakhir dan klasifikasikan\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1a3a213",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_gru = LSTMModel(input_size, hidden_size, num_layers, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f2e9e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# menagtur dan melakukanperubahan pada bobot di dalam model berdasarkan loss pada langkah sebelumnya\n",
    "optimizer_gru = torch.optim.Adam(model_gru.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e65647b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [100/624], Loss: 1.7655\n",
      "Epoch [1/10], Step [200/624], Loss: 1.1046\n",
      "Epoch [1/10], Step [300/624], Loss: 0.7458\n",
      "Epoch [1/10], Step [400/624], Loss: 0.7427\n",
      "Epoch [1/10], Step [500/624], Loss: 0.5491\n",
      "Epoch [1/10], Step [600/624], Loss: 0.4781\n",
      "Epoch [1/10], Loss: 0.3915\n",
      "Epoch [2/10], Step [100/624], Loss: 0.5722\n",
      "Epoch [2/10], Step [200/624], Loss: 0.3852\n",
      "Epoch [2/10], Step [300/624], Loss: 0.4179\n",
      "Epoch [2/10], Step [400/624], Loss: 0.3614\n",
      "Epoch [2/10], Step [500/624], Loss: 0.2472\n",
      "Epoch [2/10], Step [600/624], Loss: 0.4895\n",
      "Epoch [2/10], Loss: 0.3234\n",
      "Epoch [3/10], Step [100/624], Loss: 0.2880\n",
      "Epoch [3/10], Step [200/624], Loss: 0.3080\n",
      "Epoch [3/10], Step [300/624], Loss: 0.2358\n",
      "Epoch [3/10], Step [400/624], Loss: 0.2892\n",
      "Epoch [3/10], Step [500/624], Loss: 0.2910\n",
      "Epoch [3/10], Step [600/624], Loss: 0.2136\n",
      "Epoch [3/10], Loss: 0.2367\n",
      "Epoch [4/10], Step [100/624], Loss: 0.3249\n",
      "Epoch [4/10], Step [200/624], Loss: 0.2566\n",
      "Epoch [4/10], Step [300/624], Loss: 0.1935\n",
      "Epoch [4/10], Step [400/624], Loss: 0.1560\n",
      "Epoch [4/10], Step [500/624], Loss: 0.3099\n",
      "Epoch [4/10], Step [600/624], Loss: 0.2706\n",
      "Epoch [4/10], Loss: 0.2355\n",
      "Epoch [5/10], Step [100/624], Loss: 0.1668\n",
      "Epoch [5/10], Step [200/624], Loss: 0.2366\n",
      "Epoch [5/10], Step [300/624], Loss: 0.2582\n",
      "Epoch [5/10], Step [400/624], Loss: 0.2025\n",
      "Epoch [5/10], Step [500/624], Loss: 0.2263\n",
      "Epoch [5/10], Step [600/624], Loss: 0.1267\n",
      "Epoch [5/10], Loss: 0.2492\n",
      "Epoch [6/10], Step [100/624], Loss: 0.2387\n",
      "Epoch [6/10], Step [200/624], Loss: 0.2185\n",
      "Epoch [6/10], Step [300/624], Loss: 0.1799\n",
      "Epoch [6/10], Step [400/624], Loss: 0.1550\n",
      "Epoch [6/10], Step [500/624], Loss: 0.2264\n",
      "Epoch [6/10], Step [600/624], Loss: 0.1316\n",
      "Epoch [6/10], Loss: 0.2575\n",
      "Epoch [7/10], Step [100/624], Loss: 0.1739\n",
      "Epoch [7/10], Step [200/624], Loss: 0.2570\n",
      "Epoch [7/10], Step [300/624], Loss: 0.2226\n",
      "Epoch [7/10], Step [400/624], Loss: 0.1471\n",
      "Epoch [7/10], Step [500/624], Loss: 0.1512\n",
      "Epoch [7/10], Step [600/624], Loss: 0.1227\n",
      "Epoch [7/10], Loss: 0.2061\n",
      "Epoch [8/10], Step [100/624], Loss: 0.1820\n",
      "Epoch [8/10], Step [200/624], Loss: 0.1572\n",
      "Epoch [8/10], Step [300/624], Loss: 0.2665\n",
      "Epoch [8/10], Step [400/624], Loss: 0.1373\n",
      "Epoch [8/10], Step [500/624], Loss: 0.1566\n",
      "Epoch [8/10], Step [600/624], Loss: 0.1601\n",
      "Epoch [8/10], Loss: 0.2757\n",
      "Epoch [9/10], Step [100/624], Loss: 0.1186\n",
      "Epoch [9/10], Step [200/624], Loss: 0.2358\n",
      "Epoch [9/10], Step [300/624], Loss: 0.1693\n",
      "Epoch [9/10], Step [400/624], Loss: 0.1368\n",
      "Epoch [9/10], Step [500/624], Loss: 0.1672\n",
      "Epoch [9/10], Step [600/624], Loss: 0.1046\n",
      "Epoch [9/10], Loss: 0.1350\n",
      "Epoch [10/10], Step [100/624], Loss: 0.1931\n",
      "Epoch [10/10], Step [200/624], Loss: 0.1854\n",
      "Epoch [10/10], Step [300/624], Loss: 0.1007\n",
      "Epoch [10/10], Step [400/624], Loss: 0.1738\n",
      "Epoch [10/10], Step [500/624], Loss: 0.1440\n",
      "Epoch [10/10], Step [600/624], Loss: 0.1038\n",
      "Epoch [10/10], Loss: 0.1477\n"
     ]
    }
   ],
   "source": [
    "# Proses pelatihan model\n",
    "total_step_gru = len(train_loader)\n",
    "\n",
    "for epoch_gru in range(num_epochs):\n",
    "    for i, (images_gru, labels_gru) in enumerate(train_loader):\n",
    "        # mengubah bentuk data menjadi (batch_size, sequence_length, input_size)\n",
    "        images_gru = images_gru.squeeze(1).to(device)  \n",
    "        labels_gru = labels_gru.to(device)\n",
    "        labels_gru = labels_gru - 1  # menyesuaikan label ke rentang dari 0-25\n",
    "        \n",
    "        # Forward pass - lakukan prediksi\n",
    "        outputs_gru = model_gru(images_gru)\n",
    "        loss_gru = criterion(outputs_gru, labels_gru)\n",
    "        \n",
    "        # Backward dan optimisasi - update bobot model\n",
    "        optimizer_gru.zero_grad()\n",
    "        loss_gru.backward()\n",
    "        optimizer_gru.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch_gru+1}/{num_epochs}], Step [{i+1}/{total_step_gru}], Loss: {loss_gru.item():.4f}')\n",
    "    \n",
    "    print(f'Epoch [{epoch_gru+1}/{num_epochs}], Loss: {loss_gru.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b2cf0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the GRU model: 93.08%\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "with torch.no_grad():\n",
    "    n_correct_gru = 0\n",
    "    n_samples_gru = 0\n",
    "    for images_gru, labels_gru in test_loader:\n",
    "        images_gru = images_gru.squeeze(1).to(device)\n",
    "        labels_gru = labels_gru.to(device)\n",
    "        labels_gru = labels_gru - 1\n",
    "        \n",
    "        outputs_gru = model_gru(images_gru)\n",
    "        _, predicted_gru = torch.max(outputs_gru.data, 1)\n",
    "        \n",
    "        n_samples_gru += labels_gru.size(0)\n",
    "        n_correct_gru += (predicted_gru == labels_gru).sum().item()\n",
    "\n",
    "    acc_gru = 100.0 * n_correct_gru / n_samples_gru\n",
    "    print(f'Accuracy of the GRU model: {acc_gru:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61d3217",
   "metadata": {},
   "source": [
    "# Kesimpulan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1aab8e",
   "metadata": {},
   "source": [
    "- Data yang digunakan pada kasus ini yaitu EMNIST yaitu data huruf. untuk sumber data sendiri saya menggunakan data dari dataset EMNIST yang telah tersedia pada torchvision.\n",
    "\n",
    "- Dampak yang terjadi akibat pergantian dataset yaitu terdapat pada hyperparameter, dimana setiap nilai hyperparameter diatur kembali untuk menyesuaikan dengan dataset yang ada, baik itu dari jumlah dataset, jenis dataset atauapun hal lainnya. selain itu dampah terhadap peforma adalah pada model RNN akurasi yang didapatkan yaitu 84% dengan epoch 5, sedangkan untuk LSTM mendapatkan akurasi 92.84% dengan epoch 10 dengan nilai epoch yang turun secara signifikan dan tidak mengalami kenaikan yang signifikan kembali, dan model GRU mendapatkan akurasi sebesar 93% dnegan total epoch yaitu sama seperti LSTM 10.\n",
    "\n",
    "- tidak terdapat kendala dalam modifikasi kode, karena tidak banyak terdapat perubahan dalam kode sebelumnya. perubahan hanya terjadi pada saat pelatihan dan testing model. dimana terdapat tambahan code yaitu \"labels = labels - 1\" hal ini berfungsi untuk menyesuaikan range data dimana mulai dari 0-25\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
